{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will learn about the basic binary classification problem where our end result is in yes or no format.\n",
    "here we will try to build a model which help us to identify if given message is a spam or not\n",
    "\n",
    "Steps:\n",
    "1. Import Necessary Libraries\n",
    "2. Create a Custom Dataset\n",
    "3. PreProcess the Data\n",
    "4. Build the Neural Network Model\n",
    "5. Evaluate the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a Custom Dataset:\n",
    "<span>Here we have created a custom data set which help us to perform the classification</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'message': [\n",
    "        \"Congratulations, you've won a free ticket to the Bahamas! Call now!\",\n",
    "        \"Hey, are we still meeting at the cafe tomorrow?\",\n",
    "        \"Get cheap meds online, click here for a discount!\",\n",
    "        \"Reminder: Your appointment is scheduled for next Wednesday.\",\n",
    "        \"Win a $1000 gift card by completing this survey!\",\n",
    "        \"Don't forget to submit the assignment by tonight.\",\n",
    "        \"You've been selected for a special prize! Visit our website.\",\n",
    "        \"Let's catch up over lunch this weekend.\",\n",
    "        \"Limited time offer, buy one get one free!\",\n",
    "        \"Your order has been shipped and will arrive by Friday.\"\n",
    "    ],\n",
    "    'label': ['spam', 'ham', 'spam', 'ham', 'spam', 'ham', 'spam', 'ham', 'spam', 'ham']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. PreProcess the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Congratulations, you've won a free ticket to t...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey, are we still meeting at the cafe tomorrow?</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Get cheap meds online, click here for a discount!</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reminder: Your appointment is scheduled for ne...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Win a $1000 gift card by completing this survey!</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message label\n",
       "0  Congratulations, you've won a free ticket to t...  spam\n",
       "1    Hey, are we still meeting at the cafe tomorrow?   ham\n",
       "2  Get cheap meds online, click here for a discount!  spam\n",
       "3  Reminder: Your appointment is scheduled for ne...   ham\n",
       "4   Win a $1000 gift card by completing this survey!  spam"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Congratulations, you've won a free ticket to t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey, are we still meeting at the cafe tomorrow?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Get cheap meds online, click here for a discount!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reminder: Your appointment is scheduled for ne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Win a $1000 gift card by completing this survey!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  label\n",
       "0  Congratulations, you've won a free ticket to t...      1\n",
       "1    Hey, are we still meeting at the cafe tomorrow?      0\n",
       "2  Get cheap meds online, click here for a discount!      1\n",
       "3  Reminder: Your appointment is scheduled for ne...      0\n",
       "4   Win a $1000 gift card by completing this survey!      1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode labels\n",
    "encoder = LabelEncoder()\n",
    "df['label'] = encoder.fit_transform(df['label']) # we have converted the spam or ham value to a numeric values\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['message'], df['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    Don't forget to submit the assignment by tonight.\n",
       "0    Congratulations, you've won a free ticket to t...\n",
       "7              Let's catch up over lunch this weekend.\n",
       "2    Get cheap meds online, click here for a discount!\n",
       "9    Your order has been shipped and will arrive by...\n",
       "4     Win a $1000 gift card by completing this survey!\n",
       "3    Reminder: Your appointment is scheduled for ne...\n",
       "6    You've been selected for a special prize! Visi...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train # X_train is our data corpus which contain the all available text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text and convert to sequences\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# We are fitting the all text data into tokenizer memory this will help us to convert our text data into numaric values as machine do not understand the string \n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train) # Get numeric values for X_train data\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)  # Get numeric values for X_test data\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "maxlen = 50 # this is our max length of the sentence\n",
    "X_train_pad = pad_sequences(X_train_seq, padding='post', maxlen=maxlen)\n",
    "X_test_pad = pad_sequences(X_test_seq, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a',\n",
       " 2: 'by',\n",
       " 3: 'for',\n",
       " 4: 'to',\n",
       " 5: 'the',\n",
       " 6: \"you've\",\n",
       " 7: 'this',\n",
       " 8: 'your',\n",
       " 9: 'been',\n",
       " 10: \"don't\",\n",
       " 11: 'forget',\n",
       " 12: 'submit',\n",
       " 13: 'assignment',\n",
       " 14: 'tonight',\n",
       " 15: 'congratulations',\n",
       " 16: 'won',\n",
       " 17: 'free',\n",
       " 18: 'ticket',\n",
       " 19: 'bahamas',\n",
       " 20: 'call',\n",
       " 21: 'now',\n",
       " 22: \"let's\",\n",
       " 23: 'catch',\n",
       " 24: 'up',\n",
       " 25: 'over',\n",
       " 26: 'lunch',\n",
       " 27: 'weekend',\n",
       " 28: 'get',\n",
       " 29: 'cheap',\n",
       " 30: 'meds',\n",
       " 31: 'online',\n",
       " 32: 'click',\n",
       " 33: 'here',\n",
       " 34: 'discount',\n",
       " 35: 'order',\n",
       " 36: 'has',\n",
       " 37: 'shipped',\n",
       " 38: 'and',\n",
       " 39: 'will',\n",
       " 40: 'arrive',\n",
       " 41: 'friday',\n",
       " 42: 'win',\n",
       " 43: '1000',\n",
       " 44: 'gift',\n",
       " 45: 'card',\n",
       " 46: 'completing',\n",
       " 47: 'survey',\n",
       " 48: 'reminder',\n",
       " 49: 'appointment',\n",
       " 50: 'is',\n",
       " 51: 'scheduled',\n",
       " 52: 'next',\n",
       " 53: 'wednesday',\n",
       " 54: 'selected',\n",
       " 55: 'special',\n",
       " 56: 'prize',\n",
       " 57: 'visit',\n",
       " 58: 'our',\n",
       " 59: 'website'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numeric value of each word \n",
    "tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 11,  4, 12,  5, 13,  2, 14,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [15,  6, 16,  1, 17, 18,  4,  5, 19, 20, 21,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What this random numbers are ...? \n",
    "# don't worry our tokenizer know these i.e 10 = don't , 11 = forget \n",
    "# See above cell for reference and zero at the is used to maintain same length of the all elements which is required for or model\n",
    "X_train_pad[:2] # showing first two records of X_train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Build the Neural Network Model\n",
    "\n",
    "Explanation:\n",
    "Data Preparation: We encode the labels ('spam' and 'ham') into numerical form using LabelEncoder. Text messages are tokenized using Tokenizer from Keras and then padded to ensure uniform length for neural network input.\n",
    "\n",
    "Model Building:\n",
    "\n",
    "An Embedding layer converts text sequences into dense vectors of fixed size.\n",
    "GlobalAveragePooling1D averages over the sequence dimension to flatten the input.\n",
    "Two Dense layers with relu and sigmoid activations for classification.\n",
    "Training and Evaluation: The model is trained using binary_crossentropy as the loss function and adam optimizer. Accuracy is evaluated on the test set.\n",
    "\n",
    "Adjust the model architecture, tokenizer parameters, and training epochs as needed based on performance and specific requirements. This example provides a basic framework for text classification using TensorFlow with your provided data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_2      │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_2      │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=64, input_length=maxlen), #Convert integer-encoded token sequences into dense vectors (embeddings).\n",
    "    tf.keras.layers.GlobalAveragePooling1D(), # GlobalAveragePooling1D averages over the sequence dimension to flatten the input.\n",
    "    tf.keras.layers.Dense(64, activation='relu'), # Two Dense layers with relu and sigmoid activations for classification.\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid') ## return single response at the end\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy', # The model is trained using binary_crossentropy as the loss function and adam optimizer\n",
    "              metrics=['accuracy']) # Accuracy is evaluated on the test set\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.6636 - val_accuracy: 1.0000 - val_loss: 0.6865\n",
      "Epoch 2/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.6615 - val_accuracy: 1.0000 - val_loss: 0.6860\n",
      "Epoch 3/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.6593 - val_accuracy: 1.0000 - val_loss: 0.6856\n",
      "Epoch 4/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.6570 - val_accuracy: 1.0000 - val_loss: 0.6851\n",
      "Epoch 5/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.6546 - val_accuracy: 1.0000 - val_loss: 0.6846\n",
      "Epoch 6/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.6521 - val_accuracy: 1.0000 - val_loss: 0.6841\n",
      "Epoch 7/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.6493 - val_accuracy: 1.0000 - val_loss: 0.6836\n",
      "Epoch 8/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.6464 - val_accuracy: 1.0000 - val_loss: 0.6830\n",
      "Epoch 9/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.6434 - val_accuracy: 1.0000 - val_loss: 0.6823\n",
      "Epoch 10/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.6403 - val_accuracy: 1.0000 - val_loss: 0.6816\n",
      "Epoch 11/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.6371 - val_accuracy: 1.0000 - val_loss: 0.6810\n",
      "Epoch 12/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.6338 - val_accuracy: 1.0000 - val_loss: 0.6803\n",
      "Epoch 13/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.6304 - val_accuracy: 1.0000 - val_loss: 0.6797\n",
      "Epoch 14/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.6268 - val_accuracy: 1.0000 - val_loss: 0.6790\n",
      "Epoch 15/15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.6231 - val_accuracy: 1.0000 - val_loss: 0.6783\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train_pad,  # our trained data\n",
    "                    y_train,  # levels either spam or not\n",
    "                    epochs=15,  # try to learn data 10 times\n",
    "                    batch_size=32,  # try with 32 items in each step\n",
    "                    # More we can learn here Tutorials\\4 ML-Models\\1 Train a Model.md ## Model fit perms\n",
    "                    validation_split=0.2,\n",
    "                    verbose=1 \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5000 - loss: 0.6835\n",
      "Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_pad, y_test)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
